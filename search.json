[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quarto CRC Book",
    "section": "",
    "text": "Preface\nThis is a Quarto book."
  },
  {
    "objectID": "index.html#software-conventions",
    "href": "index.html#software-conventions",
    "title": "Quarto CRC Book",
    "section": "Software conventions",
    "text": "Software conventions\n\n1 + 1\n\n2\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Quarto CRC Book",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nBlah, blah, blah…"
  },
  {
    "objectID": "winequality.html#bussiness-understanding",
    "href": "winequality.html#bussiness-understanding",
    "title": "1  ———————– TUGAS PROYEK SAINS DATA ————————",
    "section": "1.1 BUSSINESS UNDERSTANDING",
    "text": "1.1 BUSSINESS UNDERSTANDING\n\n\n1.1.1 TUJUAN BISNIS\nMeningkatkan nilai jual salah satu produk wine yaitu produk red wine Vinho Verde dengan meningkatkan kualitas produk red wine milik perusahaan Vinho Verde\n\n\n1.1.2 TUJUAN PENAMBANGAN DATA\nMenilai kualitas pada anggur merah (red wine) yang diproduksi oleh perusahaan vinho verde dengan menggunakan model klasifikasi, kualitas anggur dapat dinyatakan dengan menentukan nilai regressi seperti berikut:\n\nKualitas Anggur lebih besar sama dengan 7 maka dinyatakan “good” atau bernilai 1\nKualitas Anggur di bawah angka 7 maka dinyatakan “not good” atau bernilai 0\n\nUntuk menentukan kualitas dari anggur dapat dilihat dari ciri-ciri sebagai berikut:\n\n\n1.1.3 DESKRIPSI FITUR\n\nFixed acidity (Kadar asam tartarat pada anggur) (g/dm3)\nVolatile acidity (Kadar asam asetat pada anggur)(g/dm3)\nCitric acid (Kadar asam sitrat dalam anggur) (g/dm3)\nResidual Sugar(Kadar sisa gula pada wine) (g/dm3)\nChlorides (Kadar natrium klorida dalam anggur) (g/dm3)\nFree sulfur dioxide (Tingkat sulfur dioksida bebas dalam anggur) (mg/dm3)\nTotal sulfur dioxide (SO2 Total = SO2 bebas + SO2 bereaksi) (mg/dm3)\nDensity(Kepadatan anggur) (g/cm3)\npH(tingkat keasaman anggur)(Range: 0 - 14)\nSulphates(Kadar kalium sulfat dalam anggur)(g/dm3)\nAlcohol(Konsentrasi alkohol dalam anggur)(% vol. )\n\n\n\n1.1.4 RENCANA PROYEK\nUntuk mencapai Tujuan Penambangan Data serta Tujuan Bisnis diatas. Maka, terdapat serangkaian langkah-langkah yang perlu dilakukan diantaranya: - Mengumpulkan Sumber Daya : Sumber Daya yang akan diolah sebagai masukan adalah data penilaian serta kandungan dari salah satu produk anggur milik perusahaan vinho verde yaitu anggur merah . Data yang dimasukkan adalah data yang telah di berikan label berdasarkan penilaian dari anggur merah serta beberapa ciri didalam anggur yang mendukung pengelompokkan anggur berdasarkan label nya\n\nMengelompokkan Sumber Daya : Sesui dengan tujuan penambangan data nya. Maka dari itu, diasumsikan terdapat dua jenis kategori dari kualitas anggur merah ini yaitu anggur merah dengan kualitas baik dan buruk sehingga banyak kelas dari sebelumnya berupa rentang angka dari 1 sampai 10 menjadi data tipe binary yang hanya memiliki dua jenis, yaitu 1 (baik) dan 0 (buruk)\nAnalisis Sumber Daya : Analisis perlu dilakukan dikarenkan untuk mengetahui tahap-tahap pre-processing apa saja yang diperlukan untuk mengatasi berkurangnya kualitas data yang akan diolah, terdapat beberapa analisis yang perlu dilakukan seperti : analisis tipe data apa saja didalm data, analisis missing values pada data, analsis oulier pada data serta analsis proporsi jumlah kelas didalm data.\nPre-processing Sumber Daya : sebelum memasuki tahap modeling, data terlebih dahulu harus dalam kualitas yang sangat baik dengan menangani permasalahan pada data yang telah diketahui dan dianalisis pada tahap analisis sumber daya. Dengan begitu, pada tahap ini telah diketahui apa saja langkah-langkah yang harus dilakukan untuk meningkatkan kualitas dari data, seperti penyeimbangan jumlah kelas dalam data, penanganan missing values dan outlier pada data. Selain penanganan terhadap kesalahan dalam data, pada tahap ini dilakukan juga split atau pembagian data menjadi 2 bagian yatu data latih(training) dan data uji(testing), pembagian perlu dilakukan untuk melatih model untuk menentukan model yang terbaik untuk data nantinya di tahap selanjutnya. Pada tahap ini dapat ditambahkan pemilihan fitur terbaik dengan me-ranking setiap fitur dalam data sehingga dapat diketahui fitur-fitur apa saja yang paling berpengaruh dan paling tidak berpengaruh pada penentuan kelas pada data.\nSkenario Percobaan : tahap ini digunakan untuk melakukan pencarian terhadap metode dan parameter nya yang cocok pada data. Dikatakan cocok dengan data jika akurasi yang didapatkan dari metode dan paramter tersebut dinilai besar dan lebih baik dari metode dan parameter nya yang lain. Untuk mengetahui nya maka perlu dilakukan percobaan untuk mengetahui metode dan parameter nya yang dapat menghasilkan nilai akurasi yang besar.\nModelling : setalah data dalam keadaan berkualitas yang baik, maka untuk melakukan prediksi kualitas anggur merah sebelumnya perlu dilakukan pemilihan metode serta parameter terbaik nya. Pada tahap ini, metode serta parameter yang dinilai terbaik untuk data di terapkan pada data setelah itu ekstraksi model dilakukan dengan berisikan metode serta parameter terbaik nya yang disimpan dalam sebuah file, yang dimana nanti untuk melakukan prediksi pada data uji model ini lah yang akan di load dan diterapkan.\nEvaluasi Model : Pada tahap ini model terbaik yang telah diciptakan dilakukan evaluasi dengan melihat akurasi yang didapatkannya serta dapat dengan membuat tabel kebingungan serta grafik kurva ROC-AUC dari hasil modelling data dengan metode serta parameter terbaik nya. Disini, hasil modelling dapat dinilai dan evaluasi tingkat keakuratan nya\nDeployment : Disini prediski pada data uji dapat diterapkan dengan mengimpementasikan model terbaik yang telah di ekspor tadi kedalam data baru yang belum diketahui kelas nya apakah termasukka kedalm kelas kualitas baik atau buruk. Dimulai dengan input data yang akan diuji lalu model terbaik yang telah di load lalu diterapkan dalam data uji yang barusan diinputkan sehingga dapat melakukan prediksi kualitas anggur merah terhadap data uji yang baru tersebut."
  },
  {
    "objectID": "winequality.html#data-understanding",
    "href": "winequality.html#data-understanding",
    "title": "1  ———————– TUGAS PROYEK SAINS DATA ————————",
    "section": "1.2 DATA UNDERSTANDING",
    "text": "1.2 DATA UNDERSTANDING\n\n\n1.2.1 TEKNIK PENGUMPULAN DATA\nData yang digunakan pada proyek ini adalah data dari salah satu produk unik berupa red wine yang diproduksi oleh perusahaan vinho verde dari wilayah Minho (barat laut) Portugal.Data dikumpulkan dari Mei 2004 hingga Februari 2007 hanya dengan menggunakan proteksi penunjukan sampel asal yang diuji di badan sertifikasi resmi (CVRVV).CVRVV adalah organisasi antar-profesional dengan tujuan meningkatkan kualitas dan pemasaran vinho verde. Datanya adalah dicatat oleh sistem komputerisasi (iLab), yang secara otomatis mengelola proses pengujian sampel anggur mulai dari permintaan produsen hingga analisis laboratorium dan sensorik. Setiap entri menunjukkan tes tertentu (analitis atau sensorik) dan database akhir diekspor ke dalam satu lembar (.csv). Tentang preferensi, setiap sampel dievaluasi oleh minimal tiga penilai sensorik (menggunakan pengecap buta),yang menilai anggur dalam skala yang berkisar dari 0 (sangat buruk) hingga 10 (sangat baik).\n\n# Berikut Library apa saja yang perlu di import untuk membantu pemrosesan pada data\nimport numpy as np\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom imblearn.over_sampling import RandomOverSampler\nfrom collections import Counter\nimport joblib\nfrom sklearn.model_selection import train_test_split\nimport pickle\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score,roc_curve\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\nimport matplotlib.pyplot as plt\n\n\n# Me-load file red-wine dengan ekstensi csv \ndata = pd.read_csv('winequality-red.csv')\n\n\n# Untuk Mengetahui Keunikan Kelas Dalam Data\ndata['quality'].unique()\n\narray([5, 6, 7, 4, 8, 3], dtype=int64)\n\n\n\n\n1.2.2 JUMLAH DATASET\nJumlah Dataset sebanyak 1599 record. Dikarenakan pada data red wine pada kolom ‘quality’ berisikan rentang nilai dari 0 sampai 10. Maka, untuk menentukan kualitas baik atau buruk nya red wine dapat dengan memasukkan data dengan rentang 0 sampai 6 termasuk kedalam golongan kualitas anggur yang buruk (0) dan memasukkan data dengan rentang 7 sampai 10 kedalam golongan kualitas anggur yang baik (1)\nBerikut Hasil pembagian kelas didalm data : - Berkualitas buruk (0) = 1382 data - Berkualitas baik (1) = 217 data\n\n# untuk membagi data menjadi fitur dan target\nfitur = data.drop('quality', axis= 1)\ntarget = data['quality'].apply(lambda y_value: 1 if y_value &gt;= 7 else 0)\n\n\n#untuk menghitung berapa banyak kelas dan jumlah nya dalam sekumpulan data\ntarget.value_counts()\n\nquality\n0    1382\n1     217\nName: count, dtype: int64\n\n\n\n\n1.2.3 ANALISIS STATISTIK\nAnalisis statistik pada data adalah proses mengumpulkan, menyusun, meringkas, menginterpretasi, dan membuat kesimpulan dari data menggunakan metode statistik. Tujuan utamanya adalah untuk memahami pola, tren, atau hubungan di dalam data yang telah dikumpulkan.\nDeskripsi Statistik: Ini mencakup teknik untuk merangkum dan menggambarkan data, seperti mean (rata-rata), median (nilai tengah), modus (nilai yang paling sering muncul), kuartil, dan deviasi standar.\nDeskripsi Statistik digunakan untuk memberikan nilai statistik deskriptif dari suatu dataframe dengan hasil sebagai berikut- :\n\nCount : jumlah data yang bernilai didalam kolom.\nMean : Nilai rata-rata nilai setiap kolom\nstd (standar deviasi) : Sebaran data, standar deviasi yang tinggi menunjukka bahwa data cenderung lebih tersebar.\nMin : menunjukkan nilai terkecil pada setiap kolom\n25% atau Q1 : Menunjukkan kuartil pertama, nilai yang membagi 25% data terandah.\n50% : Median atau Q2, nilai tengah dari data .\n75% atau Q3 :Nilai yang membagi 75% data terendah atau batas atas .\n\nmax : Nilai terbesar dalams etiap kolom.\n\n\ndata.describe()\n\n\n\n\n\n\n\n\nfixed acidity\nvolatile acidity\ncitric acid\nresidual sugar\nchlorides\nfree sulfur dioxide\ntotal sulfur dioxide\ndensity\npH\nsulphates\nalcohol\nquality\n\n\n\n\ncount\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n1599.000000\n\n\nmean\n8.319637\n0.527821\n0.270976\n2.538806\n0.087467\n15.874922\n46.467792\n0.996747\n3.311113\n0.658149\n10.422983\n5.636023\n\n\nstd\n1.741096\n0.179060\n0.194801\n1.409928\n0.047065\n10.460157\n32.895324\n0.001887\n0.154386\n0.169507\n1.065668\n0.807569\n\n\nmin\n4.600000\n0.120000\n0.000000\n0.900000\n0.012000\n1.000000\n6.000000\n0.990070\n2.740000\n0.330000\n8.400000\n3.000000\n\n\n25%\n7.100000\n0.390000\n0.090000\n1.900000\n0.070000\n7.000000\n22.000000\n0.995600\n3.210000\n0.550000\n9.500000\n5.000000\n\n\n50%\n7.900000\n0.520000\n0.260000\n2.200000\n0.079000\n14.000000\n38.000000\n0.996750\n3.310000\n0.620000\n10.200000\n6.000000\n\n\n75%\n9.200000\n0.640000\n0.420000\n2.600000\n0.090000\n21.000000\n62.000000\n0.997835\n3.400000\n0.730000\n11.100000\n6.000000\n\n\nmax\n15.900000\n1.580000\n1.000000\n15.500000\n0.611000\n72.000000\n289.000000\n1.003690\n4.010000\n2.000000\n14.900000\n8.000000\n\n\n\n\n\n\n\n\n\n1.2.4 DESKRIPSI FITUR\n\n\nFixed acidity (Kadar asam tartarat pada anggur) (g/dm3)\nAsam tetap (Fixed acidity) yang dominan ditemukan dalam anggur mengacu pada total asam-asam yang terdapat dalam anggur yang tidak teruapkan selama fermentasi atau proses lainnya seperti tartarat, malat, sitrat, dan suksinat. Tingkat masing-masing yang ditemukan dalam anggur bisa sangat bervariasi tetapi dalam secara umum orang akan mengharapkan untuk melihat 1.000 hingga 4.000 mg/L asam tartarat, 0 hingga 8.000 mg/L asam malat, 0 hingga 500 mg/L asam sitrat, dan 500 hingga 2.000 mg/L asam suksinat. Secara umum, kadar fixed acidity yang ideal dalam anggur merah berkisar antara 5 hingga 6 gram per liter.\nVolatile acidity (Kadar asam asetat pada anggur)(g/dm3)\nVolatil acidity atau keasaman yang mudah menguap dalam anggur mengacu pada kandungan asam-asam yang bisa menguap pada suhu ruangan. Asam-asam ini, seperti asam asetat, terutama berkontribusi pada karakteristik rasa dan aroma anggur. Asam asetat adalah salah satu dari beberapa komponen yang memberikan rasa pada anggur. Kadar volatile acidity yang dianggap “terbaik” dalam anggur bervariasi tergantung pada jenis anggur, gaya pembuatan anggur, dan preferensi individu. Secara umum, kandungan VA yang diinginkan dalam anggur merah, batasnya cenderung sedikit lebih tinggi, mungkin sekitar 0,5 gram per liter.\nCitric acid (Kadar asam sitrat dalam anggur)(g/dm3)\nAsam Sitrat adalah asam yang memberikan kontribusi pada rasa asam yang lembut pada anggur. Asam sitrat memiliki banyak kegunaan dalam produksi anggur. Asam sitrat adalah bahan organik lemah asam, yang sering digunakan sebagai pengawet alami atau bahan tambahan pada makanan atau minuman untuk menambah rasa asam pada makanan. Kadar asam sitrat dalam anggur merah bisa bervariasi, namun secara umum, anggur merah cenderung memiliki kadar asam sitrat yang lebih rendah dibandingkan dengan jenis asam lainnya seperti asam tartarat. Kandungan asam sitrat dalam anggur merah biasanya berkisar antara 0,1 hingga 0,7 gram per liter.\nResidual Sugar(Kadar sisa gula pada wine)(g/dm3)\nGula Residu berasal dari gula anggur alami yang tersisa dalam anggur setelahnya fermentasi alkohol selesai. Itu diukur dalam gram per liter. Sisa kadar gula bervariasi pada berbagai jenis anggur. Anggur kering memiliki kadar residual sugar yang rendah, biasanya kurang dari 10 gram per liter (g/L). Anggur kering memiliki sedikit rasa manis.\nChlorides (Kadar natrium klorida dalam anggur)(g/dm3)\nKlorida adalah salah satu komponen kimia yang bisa ditemukan dalam anggur. Kadar klorida dalam anggur dapat berasal dari air irigasi, tanah tempat anggur tumbuh, atau dari pupuk yang digunakan selama pertumbuhan tanaman. Kandungan klorida ini bisa mempengaruhi karakteristik dan kualitas anggur. Maksimal konsentrasi klorida dalam anggur sekitar 0,20 - 0,60 g/L\nFree sulfur dioxide (Tingkat sulfur dioksida bebas dalam anggur)(mg/dm3)\nSulfur dioksida (SO2) adalah keadaan dimana aat sulfur dioksida larut dalam anggur, sebagian dari sulfurnya bereaksi menjadi bentuk bebas. Kadar SO2 bebas yang dianggap ideal dalam anggur merah dapat bervariasi tergantung pada beberapa faktor, termasuk jenis anggur, kondisi penyimpanan, dan preferensi pembuat anggur.Secara umum, kadar SO2 bebas dalam anggur merah biasanya berada dalam kisaran 10 hingga 40 mg/L\nTotal sulfur dioxide (SO2 Total = SO2 bebas + SO2 bereaksi) (mg/dm3)\nTotal sulfur dioxide (SO2) adalah ukuran untuk jumlah keseluruhan sulfur dioksida yang ada dalam anggur. Sulfur dioksida digunakan secara umum sebagai bahan tambahan dalam produksi anggur untuk melindungi anggur dari oksidasi dan infeksi mikroba. Dapat dinyatakan berupa Bagian dari sulfur dioksida bebas ditambah bagian yang terikat dengan bahan kimia lain di dalamnya anggur seperti aldehida, pigmen, atau gula. Untuk anggur merah, biasanya kadar SO2 yang dianjurkan berkisar antara 30 hingga 50 mg/L (miligram per liter), tetapi angka ini dapat bervariasi berdasarkan regulasi lokal, jenis anggur, dan praktik pembuatan anggur yang digunakan oleh produsen.\nDensity(Kepadatan anggur) (g/cm3)\nDensity (kepadatan) dalam konteks anggur merujuk pada kepekatan relatif dari komponen-komponen dalam anggur, terutama gula dan alkohol yang terlarut dalam jus anggur, biasanya diukur dalam satuan Brix. Brix adalah unit yang digunakan untuk mengukur kadar padatan terlarut dalam cairan. Kadar Brix yang dianggap baik untuk anggur merah bisa berkisar antara 22 hingga 25 Brix.\npH(tingkat keasaman anggur)(Range: 0 - 14)\nTingkat keasaman dalam anggur merah adalah salah satu komponen penting yang mempengaruhi rasa dan karakteristik anggur. Keasaman dalam anggur biasanya diukur dengan pH, yang mengindikasikan tingkat keasaman relatif dalam cairan tersebut. Rentang pH yang umum untuk anggur merah adalah sekitar 3 hingga 4.\nSulphates(Kadar kalium sulfat dalam anggur)(g/dm3)\nSulfit, juga biasa disebut sulfur dioksida, adalah senyawa kimia yang mengandung ion sulfit.Sulfit adalah zat yang sering digunakan sebagai pengawet dan antioksidan dalam anggur. Ini digunakan untuk mencegah oksidasi anggur dan pertumbuhan mikroorganisme yang tidak diinginkan. Kadar sulfat yang direkomendasikan dalam anggur merah berkisar antara 10 hingga 70 miligram per liter (mg/L). Namun, peraturan tentang batas maksimum penggunaan sulfat dalam anggur dapat berbeda di berbagai negara.\nAlcohol(Konsentrasi alkohol dalam anggur)(% vol. )\nAlkohol dalam anggur adalah etanol yang dihasilkan melalui proses fermentasi gula dalam anggur oleh ragi atau mikroorganisme lainnya. Kadar alkohol dalam anggur dapat bervariasi tergantung pada beberapa faktor, seperti jenis anggur, kondisi iklim tempat tumbuhnya anggur, serta teknik pembuatan dan proses fermentasi yang digunakan. Kadar alkohol yang dianggap ideal dalam anggur merah biasanya berkisar antara 12% hingga 15%.\n\n\n# untuk mengetahui fitur apa saja dalam data\ndata.columns\n\nIndex(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol', 'quality'],\n      dtype='object')\n\n\n\n\n1.2.5 TIPE DATA\nTipe Data didalam data terdapat dua jenis yaitu Tipe data Rasio dan Tipe Data Numerik\nTIPE DATA RASIO\nadalah tipe data yang mengacu pada jenis data yang memiliki sifat kuantitatif dan memiliki nol absolut yang bermakna.Contoh tipe data rasio adalah variabel yang melibatkan pengukuran yang memiliki nol yang bermakna, seperti panjang, berat, suhu, dan waktu.Operasi aritmatika seperti penambahan, pengurangan, perkalian, dan pembagian dapat dilakukan pada tipe data rasio ini. Nilai-nilai pada tipe data rasio dapat dibandingkan dan digunakan untuk perbandingan rasio atau perbandingan persentase\nTIPE DATA NUMERIK\nadalah tipe data yang mencakup sejumlah besar nilai numerik, yang dapat berupa bilangan bulat (integer) atau bilangan pecahan (floating-point).Bilangan bulat adalah bilangan utuh tanpa bagian desimal seperti -3, 0, 7, dan sebagainya.Bilangan pecahan atau floating-point adalah bilangan dengan bagian desimal seperti 3.14, 0.5, -8.75, dan sejenisnya.Data numerik dapat digunakan untuk operasi matematika seperti penambahan, pengurangan, perkalian, pembagian, serta operasi lainnya.\nTipe data dari disetiap kolom pada data anggur merah vinho verde sebagai berikut\n\nTipe Rasio :\n\nTipe data Rasio adalah\n\n\nfixed acidity\nvolatile acidity\ncitric acid\nresidual sugar\nchlorides\nfree sulfur dioxide\ntotal sulfur dioxide\ndensity\npH\nsulphates\nalcohol\n\n\n\nTipe Numerik\n\nTipe data Nominal adalah\n\n\nquality\n\n\n\ndata.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1599 entries, 0 to 1598\nData columns (total 12 columns):\n #   Column                Non-Null Count  Dtype  \n---  ------                --------------  -----  \n 0   fixed acidity         1599 non-null   float64\n 1   volatile acidity      1599 non-null   float64\n 2   citric acid           1599 non-null   float64\n 3   residual sugar        1599 non-null   float64\n 4   chlorides             1599 non-null   float64\n 5   free sulfur dioxide   1599 non-null   float64\n 6   total sulfur dioxide  1599 non-null   float64\n 7   density               1599 non-null   float64\n 8   pH                    1599 non-null   float64\n 9   sulphates             1599 non-null   float64\n 10  alcohol               1599 non-null   float64\n 11  quality               1599 non-null   int64  \ndtypes: float64(11), int64(1)\nmemory usage: 150.0 KB\n\n\n\n\n1.2.6 IDENTIFIKASI DUPLIKAT PADA DATA\n\nDuplikat data adalah terdapat record atau baris yang identik atau sangat mirip dalam hal nilai-nilai di beberapa kolom. Ini bisa menjadi masalah karena dapat mengganggu analisis data dan mempengaruhi keakuratan hasil yang diperoleh dari query atau pemrosesan data.\nHasil Identifikasi Duplikat Data : - Didalam data red wine setelah di identifikasi di temukan duplikat data dalam tabel red wine yaitu sebanyak : 240 data\n\njumlah_duplikat = data.duplicated().sum()\nprint(\"Jumlah data duplikat:\", jumlah_duplikat)\n\nJumlah data duplikat: 240\n\n\n\n\n1.2.7 IDENTIFIKASI MISSING VALUES\nMissing Values sesuai dengan namanya yaitu keberadaan nilai yang kosong atau hilang pada data. Pada proses analsisis data hilangnya banyak data dapat menyebabkan akurasi yang dihasilkan semakin menurun.\nHasil Identifikasi Missing Values :\n\nDi dalam data sampel anggur merah setelah dilakukan pengecekan nilai tidak ditemukan data dengan nilai yang hilang (Missing Values).\n\n\n# untuk mengecek apakah terdapat missing values pada data\ndata.isnull().sum()\n\nfixed acidity           0\nvolatile acidity        0\ncitric acid             0\nresidual sugar          0\nchlorides               0\nfree sulfur dioxide     0\ntotal sulfur dioxide    0\ndensity                 0\npH                      0\nsulphates               0\nalcohol                 0\nquality                 0\ndtype: int64\n\n\n\n\n1.2.8 VISUALISASI DATA\n\n# menampilkan diagram batang setiap kolom dalam data\ndata.hist(figsize=(14, 14))\nplt.show()\n\n\n\n\n\n\n1.2.9 IDENTIFIKASI OUTLIER PDA DATA\nOutlier Pada Data adalah nilai yang berbeda dari yang lain dimana perbedaannya sangat jauh dengan sekumpulan data yang lain dalam satu kolom.Keberadaan Outlier sendiri dinilai dapat mengganggu analisis statistik dan kesimpulan yang diambil dari data karena mereka bisa menyebabkan pergeseran rata-rata atau mengganggu distribusi data secara keseluruhan. Maka dari itu, pada data red wine ini perlu dilakukan identifikasi outlier pada data. Untuk menentukan outluer pada data dapat dengan menggunakan metode Local Outlier Factor.\nHasil Identifikasi Outlier pada Data :\n\nSetelah dilakukan pengecekan outlier dengan menggunakan teknik Local Outlier Factor diketahui terdapat 31 data yang terdeteksi mengandung outlier.\n\nLOCAL OUTLIER FACTOR\n\nAdalah metode yang digunakan untuk mendeteksi outlier dalam data dengan memperhatikan konteks lokal dari setiap data poin. LOF menghitung seberapa “aneh” atau tidak biasa suatu poin data jika dibandingkan dengan tetangga-tetangganya. Poin yang memiliki LOF tinggi dibandingkan dengan tetangganya dapat dianggap sebagai outlier.\nAdapun tahap-tahp untuk mengidentifikasi outlier pada data dengan menggunakan Local Outlier Factor :\n\nHitung Jarak Antar Data\n\ndimana jarak yang dihitung adalah jarak titik yang akan dievaluasi dengan semua titik didalam satu baris. Perhitungan Jarak dilakukan menggunakan perhitungan jarak euclidean.\n\\[\n\\text{distance}(p, q) = \\sqrt{\\sum_{i=1}^{n}(p_i - q_i)^2}\n\\]\ndimana :\np = titik yang akan dievaluasi q = titik selain titik p\n\nHitung Kepadatan Lokal\n\nSetelah jarak diketahui, maka selanjutnya kepadatan lokal dari titik data tersebut perlu dihitung. Kepadatan lokal dapat dihitung dengan membandingkan jumlah titik-titik tetangga dalam jarak tertentu (radius) terhadap titik data yang sedang dievaluasi.\n\\[\n\\text{Local Density}(p) = \\frac{\\text{jumlah tetangga dalam radius}}{\\text{jumlah total data}}\n\\]\n\nHitung Local Reachability Density(LRD)\n\nHitung kepadatan jarak (reachability distance) dari titik data (p) terhadap tetangganya (q). Local Reachability Density dari titik p terhadap tetangga q dihitung sebagai rata-rata dari jarak antara q dan p terhadap tetangga q:\n\\[\n\\text{reachdist}(p, q) = \\max(\\text{distance}(p, q), \\text{radius})\n\\]\n\\[\n\\text{Local Reachability Density}(p) = \\frac{1}{\\text{jumlah tetangga}} \\sum_{q \\in N_{\\text{radius}}(p)} \\frac{\\text{reachdist}(p, q)}{\\text{density}(q)}\n\\]\ndimana: - N radius(p) adalah himpunan tetangga dalam radius tertentu radius dari titik p. - density(q) adalah kepadatan lokal dari tetangga q.\n\nHitung Nilai LOF\n\nLOF dari suatu titik data (p) dihitung sebagai rasio dari rata-rata Local Reachability Density dari tetangganya terhadap kepadatan lokalnya sendiri:\n\\[\n\\text{LOF}(p) = \\frac{1}{\\text{jumlah tetangga}} \\sum_{q \\in N_{\\text{radius}}(p)} \\frac{\\text{Local Reachability Density}(q)}{\\text{Local Reachability Density}(p)}\n\\]\ndimana :\nLOF yang tinggi menunjukkan bahwa titik tersebut memiliki kepadatan lokal yang lebih rendah dibandingkan dengan tetangganya, sehingga cenderung menjadi outlier.\nContoh Kasus, untuk mencari outlier pada data misalkan terdapat tabel seperti dibawah ini:\n\n\n\nX\nY\n\n\n\n\n1\n4\n\n\n2\n3\n\n\n3\n8\n\n\n7\n2\n\n\n5\n9\n\n\n\n\nLangkah 1 : Hitung Jarak Antar Data lalu nilai radius yang diambil adalah 5\n\n\n\n\nX\nY\nJarak\n\n\n\n\n1\n4\n1,41 ; 4,47 ; 4,47\n\n\n2\n3\n1,41 ; 3,16\n\n\n3\n8\n4,47\n\n\n5\n2\n4,47 ; 3,16 ; 4,24\n\n\n8\n5\n4,24\n\n\n\n\nLangkah 2 : Hitung jumlah tetangga dalam radius 5\n\n\n\n\nX\nY\nJumlah Tetangga\n\n\n\n\n1\n4\n3\n\n\n2\n3\n2\n\n\n3\n8\n1\n\n\n5\n2\n3\n\n\n8\n5\n1\n\n\n\n\nLangkah 3 : Hitung Local Reachability Density\n\n\n\n\nX\nY\nJarak\n\n\n\n\n1\n4\n(1,41 + 4,47 + 4,47) / 3 = 3,45\n\n\n2\n3\n(1,41 + 3,16) /2 = 2,285\n\n\n3\n8\n4,47\n\n\n5\n2\n(4,47 + 3,16 + 4,24) / 3 = 3,95\n\n\n8\n5\n4,24\n\n\n\n\nLangkah 4 : Menghitung nilai LOF data\n\n\n\n\nX\nY\nLOF\n\n\n\n\n1\n4\n(1/3,45) x ((2,285 + 4,47 + 3,95) / 3) = 1,03\n\n\n2\n3\n(1/2,285) x ((3,45 + 3,95) / 2) = 1,61\n\n\n3\n8\n(1/4,47) x ((3,45)) = 0,77\n\n\n5\n2\n(1/3,95) x ((3,45 + 2,285 + 4,24) / 3) = 0,83\n\n\n8\n5\n(1/4,24) x ((3,95)) = 0.936\n\n\n\nDengan begitu, nilai yang berkemungkinan menjadi outlier adalah baris 2 dan baris 1\nInter Pretasi Local Outlier Factor :\n\nJika LOF &gt; 1, itu menunjukkan bahwa kepadatan lokal dari titik p lebih rendah daripada rata-rata kepadatan lokal dari tetangganya. Artinya, titik tersebut memiliki sifat yang “aneh” atau berbeda dari lingkungan sekitarnya dan cenderung menjadi outlier.\nJika LOF ≈ 1, itu menunjukkan bahwa kepadatan lokal dari titik p mirip dengan rata-rata kepadatan lokal tetangganya.\nJika LOF &lt; 1, itu menunjukkan bahwa kepadatan lokal dari titik p lebih tinggi daripada rata-rata kepadatan lokal dari tetangganya, sehingga cenderung menjadi titik yang tidak aneh.\n\n\n# Membuat model LOF\nclf = LocalOutlierFactor(n_neighbors=20)  # Jumlah tetangga yang digunakan \noutlier_scores = clf.fit_predict(data) # untuk menghitung nilai LOF\n\n# Menampilkan indeks outlier\noutlier_indices = np.where(outlier_scores == -1)[0] # menampilkan indeks/baris apa saja yang memiliki oulier\nprint(\"Indeks outlier:\",outlier_indices)\nprint(\"Indeks outlier:\",len( outlier_indices))\n\nIndeks outlier: [ 324  325  354  374  396  400  442  444  480  530  535  538  559  564\n  652  773  774  911  917  923  982 1043 1079 1081 1131 1186 1235 1244\n 1478 1558 1574]\nIndeks outlier: 31\n\n\n\n\n1.2.10 IDENTIFIKASI PROPORSI JUMLAH MASING-MASING KELAS DALAM DATA\nUntuk mencapai hasil maksimal, perlu dilakukan identifikasi proporsi jumlah data dari masing-masing kelas. Dengan begitu ketidakseimbangan data disetiap kelas pada data red wine ini dapat ditangani dengan menyeimbangkan jumlah data disetiap kelasnya.\nHasil Identifikasi Proporsi Jumlah Masing-Masing Kelas dalam data :\nBerdasarkan jumlah data pada setiap kelas yang telah di definisikan sebelumnya, dapat diketahui bahwasan nya pada data jumlah masing-masing kelas tidak seimbang dengan perbandingan :\n\n86.4% dari jumlah seluruh data untuk data yang diidentifikasi memiliki kualitas yang buruk\n13.5% dari jumlah seluruh data untuk data yang diidentifikasi termasuk memiliki kualitas yang bagus.\n\n\n#untuk menghitung berapa banyak kelas dan jumlah nya dalam sekumpulan data\ntarget.value_counts()\n\nquality\n0    1382\n1     217\nName: count, dtype: int64"
  },
  {
    "objectID": "winequality.html#preprocessing-data",
    "href": "winequality.html#preprocessing-data",
    "title": "1  ———————– TUGAS PROYEK SAINS DATA ————————",
    "section": "1.3 PREPROCESSING DATA",
    "text": "1.3 PREPROCESSING DATA\n\nDari Data Understanding diatas dapat disimpulkan bahwasannya:\n\nDidalam data tidak memiliki Missing Values\nDidalam data terdapat duplikat data\nDidalam data juga terdapat outlier yang terdeteksi\nTerjadi Inbalancing pada jumlah masing-masing kelas dalam data\n\nMaka dari itu perlu dilakukan beberapa langkah preprocessing pada data seperti:\n\n1.3.1 PENANGANAN DUPLIKAT DATA\n\nSetelah dilakukan Identifikasi duplikat data pada tabel red wine. Maka, untuk melakukan penanganan pada masalah ini maka dapat dilakukan penghapusan data duplikat yang telah diidentifikasi sebelumnya di tahap data understanding\n\n# variabel data yang menyimpan data dilakukan drop atau penghapusan data yang  duplikat\ndata.drop_duplicates(inplace=True)\n\n\n\n1.3.2 PENANGANAN OUTLIER PADA DATA\nLangkah yang dapat diambil untuk menangani terdapatnya outlier pada data adalah dapat dengan menghapus baris-baris data yang di beberapa kolomnya mengandung oulier.\n\nclf = LocalOutlierFactor(n_neighbors=20)  # Jumlah tetangga yang digunakan \noutlier_scores = clf.fit_predict(data) # untuk menghitung nilai LOF\n\n# Menampilkan indeks outlier\noutlier_indices = np.where(outlier_scores == -1)[0]\nlist_from_outlier_indices = outlier_indices.tolist() # untuk mengubah tiped data pada variabel outlier_indices menjadi list\ndata_cleaned = data[outlier_scores != -1]  # Mengambil baris yang bukan outlier\n\nprint(\"Data sebelum penghapusan outlier:\",len(data))  # Menampilkan panjang dari data sebelum menghapus outlier\nprint(\"Data setelah penghapusan outlier:\", len(data_cleaned)) # Menampilkan panjang dari data sesudah menghapus outlier\n\nData sebelum penghapusan outlier: 1359\nData setelah penghapusan outlier: 1334\n\n\n\n\n1.3.3 PENANGANAN PROPORSI JUMLAH MASING-MASING KELAS PADA DATA\nDikarenakan terdapat ketidakseimbangan pada data disetiap kelasnya maka diperlukan sebuah proses balancing data agar jumlah data pada setiap kelasnya dapat seimbang untuk menanganin ketidakseimbangan data maka diperlukan suatu metode yaitu metode Random Over Sampling yang akan membuat jumlah data pada masing-masing kelas menjadi sama sehingga seimbang\n\nfitur_cleaned = data_cleaned.drop('quality', axis= 1) # memasukkan fitur selain kolom quality kedalam variabel fitur_cleaned\ntarget_cleaned = data_cleaned['quality'].apply(lambda y_value: 1 if y_value &gt;= 7 else 0) # memasukkan kolom quality kedalam variabel target_cleaned\n\nBALANCING DATA\n\nBalancing data adalah proses memastikan bahwa dataset yang digunakan untuk melakukan analisis atau pelatihan model memiliki distribusi yang seimbang di antara kelas-kelas yang berbeda. Hal ini sering kali terjadi dalam konteks klasifikasi di mana terdapat lebih sedikit contoh atau sampel untuk satu kelas dibandingkan dengan kelas lainnya. Ketika kelas-kelas dalam dataset tidak seimbang, model yang dibangun cenderung cenderung memprediksi kelas mayoritas dengan lebih baik daripada kelas minoritas, sehingga mengurangi performa model untuk kelas minoritas.\nRANDOM OVER SAMPLING\n\nRandomOverSampling adalah salah satu teknik dalam pengolahan data yang digunakan untuk menangani ketidakseimbangan dalam dataset kelas-kelas yang berbeda. Ketidakseimbangan terjadi ketika ada perbedaan signifikan dalam jumlah sampel antara kelas mayoritas dan kelas minoritas dalam dataset. Dalam RandomOverSampling, sampel dari kelas minoritas secara acak ditingkatkan untuk mencapai keseimbangan dengan kelas mayoritas. Ini dapat dilakukan dengan menduplikasi data dari kelas minoritas secara acak hingga jumlah sampelnya sebanding dengan kelas mayoritas.\nBerikut adalah langkah-langkah umum dalam melakukan RandomOverSampling:\n\nIdentifikasi Ketidakseimbangan\n\nPeriksa jumlah sampel untuk setiap kelas dalam dataset Anda untuk menentukan kelas mana yang merupakan kelas mayoritas dan kelas mana yang merupakan kelas minoritas.\n\nPenerapan RandomOverSampling\n\nSalah satu cara untuk menerapkan RandomOverSampling adalah dengan menggunakan pustaka atau modul dalam bahasa pemrograman seperti Python. Contohnya, modul imbalanced-learn menyediakan fungsi RandomOverSampler untuk melakukan oversampling secara acak.\n\n# inisialisasi RandomOverSampler\nbalancer = RandomOverSampler(random_state=42) # menyimpan metode randomoversampler untuk menyeimbangkan jumlah kelas dalam data\n\n# Menerapkan Random Over-Sampling untuk menyeimbangkan data\nfitur_balance, target_balance = balancer.fit_resample(fitur_cleaned, target_cleaned) # balancing diterapkan pada variabel fitur_cleaned dan target cleaned\n\n# Menampilkan data yang telah diseimbangkan\nprint('Hasil Penyeimbangan:', Counter(target_balance))\n\nHasil Penyeimbangan: Counter({0: 1156, 1: 1156})\n\n\nSetelah dilakukan balancing data maka data akan disimpan didalam sebuah file berekstensi pickle dengan tujuan jika ingin digunakan lagi untuk predksi maka data yang digunakan adalah data yang telah dinyatakan bersih dan memiliki kualitas data yang baik dikarenakn telah melewati pembersihand ata seperti penghapusan outlier dan penyeimbangan jumlah proporsi masing-masing kelas dalam data\n\n# Membuat DataFrame dari fitur dan target yang telah seimbang\ndata_clean = pd.concat([fitur_balance, target_balance], axis=1) \n\n# Menyimpan DataFrame ke dalam file CSV\ndata_clean.to_csv('data_bersih.csv', index=False)\n\n\n# menghitung jumlah data setelah balancing data\ncount_data = data_clean.shape[0]\nprint(\"Jumlah Data Setelah Proses Balancing :\", count_data)\n\nJumlah Data Setelah Proses Balancing : 2312\n\n\n\n# Menampilkan kelas dalam data sebelum dilakukan balancing data dengan menggunakan plot\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nsns.countplot(data=pd.DataFrame({'quality': target_cleaned}), x='quality')\nplt.title('Original Class')\n\n# Menampilkan kelas dalam data sesudah dilakukan balancing data dengan menggunakan plot\nplt.subplot(1, 2, 2)\nsns.countplot(data=pd.DataFrame({'quality': target_balance}), x='quality')\nplt.title('Random Over-Sampling With imblearn')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n1.3.4 SPLIT DATA\n\nSplit Data adalah membagi data menjadi dset data uji dan set data training(latih) sehingga data fitur dan target masing-masing dibagi menjadi set data fitur training dan set data fitur testing serta set data target training dan set data target uji\n\nset data pelatihan (training) Subset data yang digunakan untuk melatih model mesin. Model menggunakan data ini untuk belajar pola dan hubungan antara fitur (features) dan label (target).\nset data uji(test) Subset yang tidak terlibat dalam pelatihan model atau penyetelan parameter. Data ini digunakan untuk menguji kinerja model yang telah dilatih dan divalidasi. Ini memberikan perkiraan seberapa baik model akan berperforma pada data yang belum pernah dilihat sebelumnya.\n\nPada Proyek ini data testing yang digunakan adalah 1/4 data (25%) dari jumlah keseluruhan data lalu untuk data tarining yang digunakan adalah sebanyak 3/4 (75%) data dar jumlah keseluruhan data dalam dataset fungsi train_test_split yang digunakan untuk membagi dataset menjadi set pelatihan (train set) dan set pengujian (test set). Ini membantu dalam mengevaluasi kinerja model pada data yang tidak digunakan selama pelatihan.\n\nfitur_balance: Matriks fitur dari dataset yang telah di-resampled dengan menggunakan Random Over-Sampling (X_ros).\ntarget_balance: Ini adalah vektor target yang sesuai dengan fitur_balance.\ntest_size=0.25: Ini menentukan proporsi data yang akan dialokasikan untuk test set. Dalam hal ini, 25% dari total data akan digunakan sebagai test set.\nrandom_state=42: Ini digunakan untuk memastikan reproduktibilitas hasil. Jika kita memberikan nilai tertentu (dalam hal ini 42), maka setiap kali kita menjalankan fungsi ini, kita akan mendapatkan pembagian yang sama untuk set pelatihan dan set pengujian. Ini berguna ketika kita ingin hasil yang konsisten setiap kali kode dijalankan.\n\nHasil dari fungsi train_test_split adalah empat kumpulan data:\n\nfitur_train: Matriks fitur dari set pelatihan.\nfitur_test: Matriks fitur dari set pengujian.\ntarget_train: Vektor target dari set pelatihan.\ntarget_test: Vektor target dari set pengujian.\n\n\n# membagi data dengan perbandingan data latih dan uji 4:1  \nfitur_train, fitur_test, target_train, target_test = train_test_split(fitur_balance, target_balance, test_size=0.25, random_state=42)\n\n\n\n1.3.5 NORMALISASI DATA\nNormalisasi Data adalah salah satu proses dalam pre-processing data untuk mengatur dataset agar memenuhi standar tertentu. Data perlu dilakukan agar dapat mengurangi kemungkinan terjadinya redundansi data. Selain itu, normalisasi dagunakan untuk membantu menghindari anomali dalam pengolahan data dan memungkinkan desain basis data yang lebih efisien.\nMINMAX\n\nPengertian\nMinMax Scaling adalah salah satu teknik untuk melakukan normalisasi pada data dengan merubah nilai-nilai dalam kumpulan data ke dalam rentang tertentu, biasanya antara 0 dan 1. Tujuan utamanya adalah untuk menjaga skala relatif antarfitur agar tidak mendominasi satu sama lain.\nProses Min-Max Scaling dilakukan dengan langkah-langkah berikut:\n\nIdentifikasi Rentang: Tentukan rentang nilai yang ingin Anda gunakan. Biasanya, dalam Min-Max Scaling, rentang nilai yang dipilih adalah 0 hingga 1, tetapi ini bisa disesuaikan tergantung pada kasus penggunaan.\nHitung Nilai Minimum dan Maksimum: Tentukan nilai minimum (min) dan nilai maksimum (max) dari setiap fitur dalam kumpulan data yang akan dinormalisasi.\nNormalisasi: Gunakan formula rumusn Min-Max Scaling untuk mengubah nilai-nilai dalam rentang yang ditentukan.\n\nRumus Minmax Scaler\n\\[ X' = \\frac{X - min}{max - min} \\]\nDimana :\n\nX adalah nilai asli dari suatu kolom/fitur\nmin adalah nilai minimum dari suatu kolom/fitur dalam dataset\nmax adalah nilai maximum dari suatu kolom/fitur dalam dataset\nX’ adalah nilai X yang telah dinormalisasi.\n\nBerikut Contoh Penggunaan minmax pada data, sebagai berikut:\n\nTerdapat sebuah tabel dengan kolom X, seperti berikut:\n\n\n\n\nX\nX`\n\n\n\n\n2\n0\n\n\n4\n0\n\n\n3\n0\n\n\n10\n0\n\n\n\n\nUntuk melakukan normalisasi dengan Min-Max Scaling, maka perlu diidentifikasi nilai tertingggi dan terendah pada kolom. Deketahui :\n\n\nNilai terendah pada kolom X (min) = 2\nNilai tertinggi pada kolom X (max) = 10\n\n\nLalu untuk menentukan nilai X yang telah dinormalisasi maka dengan menghitung setiap baris data yang dimasukkan kedalam rumus Min-Max Scaling seperti berikut:\n\n\n\n\nX\nX`\n\n\n\n\n2\n(2 - 2) / ( 10 - 2)\n\n\n4\n(4 - 2) / ( 10 - 2)\n\n\n3\n(3 - 2) / ( 10 - 2)\n\n\n10\n(10 - 2) / ( 10 - 2)\n\n\n\n\nSehingga nilai X’ hasil normalisasi dapat diketahui seperti berikut :\n\n\n\n\nX\nX`\n\n\n\n\n2\n0\n\n\n4\n0.25\n\n\n3\n0.125\n\n\n10\n1\n\n\n\n\nmm = MinMaxScaler() # meyimpan normalisasi MinMax Scaler() dalam variabel\nmm.fit(fitur_train)\nminmax_training = mm.fit_transform(fitur_train) # melakukan normalisasi pada kolom fitur latih\nminmax_testing = mm.transform(fitur_test) # melakukan normalisasi pada kolom fitur uji\nwith open('minmax.pkl', 'wb') as file:\n    pickle.dump(mm, file)\n\n\n\n1.3.6 RANKING SETIAP FITUR DALAM DATA\nUntuk memilih fitur terbaik dapat dengan me-renking fitur-fitur didalm dataset dengan mencari nilai mutual information setiap fitur agar dapat dibandingkan diurutkan dengan fitur lainnya. Padaproyek ini digunakan metode SelectKBest dengan mencari nilai mutual information dari setiap fitur.\n\n1.3.6.1 MUTUAL INFORMATION\nMutual information (MI) adalah metrik yang berguna dalam pemilihan fitur karena mengukur seberapa banyak informasi yang saling terkait antara fitur (variabel independen) dengan variabel target (variabel dependen). Dalam konteks pemilihan fitur, kita ingin mempertahankan fitur-fitur yang memiliki hubungan yang kuat atau tinggi dalam menjelaskan variabel target.\nRumus Mutual Information (MI) between X and Y:\n\\[\n\\text{MI}(X;Y) = \\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log \\left(\\frac{p(x, y)}{p(x) \\cdot p(y)}\\right)\n\\]\nDimana:\n\nMI(X;Y) adalah mutual information antara variabel X dan Y.\np(x,y) adalah probabilitas bersama dari X=x dan Y=y.\np(x) adalah probabilitas margina X=x.\np(y) adalah probabilitas margina Y=y.\n\nDari tahap ini dihasilkan rangking dari setiap kolom atau fitur sehingga dapat mengetahui fitur-fitur yang memiliki ciri khas penting untuk data red wine itu sendiri. Pada tahap skenario percobaan nantinya akan dipilih fitur-fitur yang memiliki nilai mutual information tertinggi. Untuk memilih fitur-fitur yang terbaik dapat dimulai dengan menghapus fitur yang memiliki nilai mutual information paling rendah lalu skenario bergeser ke kiri dimana fitur yang dihapus yaitu fitur dengan mutual information terendah nomer 2 dan paling rendah. pemilihan fitur terus dilakukan pada skenario percobaan hingga mencapai akurasi tertinggi.\nContoh Kasus untuk mengurutkan kolom dengan mutual information paling tinggi hingga terendah, di berikan tabel berikut :\n\n\n\nID\nVariabel_1\nVariabel_2\nVariabel_Target\n\n\n\n\n1\n2\n3\nb\n\n\n2\n1\n2\na\n\n\n3\n3\n1\na\n\n\n4\n2\n2\nb\n\n\n5\n1\n3\na\n\n\n\n\nLangkah 1 : Hitung distribusi probabilitas\n\nUntuk Variabel_Target: &gt; - P(Target=a) = 3/5 &gt; - P(Target=b) = 2/5\nUntuk Variabel_1: &gt; - P(Variabel_1=1) = 2/5 &gt; - P(Variabel_1=2) = 2/5 &gt; - P(Variabel_1=3) = 1/5\nUntuk Variabel_2:\n\n\nP(Variabel_2=1) = 1/5\nP(Variabel_2=2) = 2/5\nP(Variabel_2=3) = 2/5\n\n\n\nLangkah 2 : Hitung Entropi\n\nEntropi(variabel_Target) = - (3/5) * log2(3/5) - (2/5) * log2(2/5) ≈ 0.971\n\n\nEntropi(Variabel_1) = - (2/5) * log2(2/5) - (2/5) * log2(2/5) - (1/5) * log2(1/5) ≈ 1.571\n\n\n\n\nEntropi(Variabel_2) = - (1/5) * log2(1/5) - (2/5) * log2(2/5) - (2/5) * log2(2/5) ≈ 1.571\n\n\n\nLangkah 3 : Hitung Conditional Entropi\n\nUntuk setiap nilai Variabel_1, hitung Entropi(Target|Variabel_1).\n\nVariabel_1\n\nConditional_Entropy(Target | Variabel_1) = P(Variabel_1=1) * Entropi(Target|Variabel_1=1) + P(Variabel_1=2) * Entropi(Target|Variabel_1=2) + P(Variabel_1=3) * Entropi(Target|Variabel_1=3)\n\n\nEntropi(Target|Variabel_1=1) = - (1/2) * log2(1/2) - (1/2) * log2(1/2) = 1.0\n\n\n\n\nEntropi(Target|Variabel_1=2) = - (1/1) * log2(1/1) - (1/1) * log2(1/1) = 0.0\n\n\n\n\nEntropi(Target|Variabel_1=3) = - (1/1) * log2(1/1) = 0.0\n\n\n\nConditional_Entropy(Target | Variabel_1) = (2/5)×1.0+(2/5)×0.0+(1/5)×0.0 = 0.4\n\n\nVariabel_2\n\nConditional_Entropy(Target | Variabel_2) = P(Variabel_2=1) * Entropi(Target|Variabel_2=1) + P(Variabel_2=2) * Entropi(Target|Variabel_2=2) + P(Variabel_2=3) * Entropi(Target|Variabel_2=3)\n\n\nEntropi(Target | Variabel_2=1) = - (1) * log2(1) = 0\n\n\n\n\nEntropi(Target | Variabel_2=2) = - (0.5) * log2(0.5) - (0.5) * log2(0.5) = 1.0\n\n\n\n\nEntropi(Target | Variabel_2=3) = - (0.5) * log2(0.5) - (0.5) * log2(0.5) = 1.0\n\n\n\nConditional_Entropy(Target | Variabel_2) = (1/5) * 0 + (2/5) * 1.0 + (2/5) * 1.0 = 0.8\n\n\nLangkah 4 : Hitung Mutual Information\n\n\n\nMutual_Information(Variabel_1;Target) = 0.971 - 0.4 = 0.571\n\n\n\n\nMutual_Information(Variabel_2;Target) = 0.971 - 0.8 = 0.171\n\n\nDengan begitu variabel yang lebih berpengaruh adalah Variabel_1 dari Variabel_2\n\n# menyimpan metode selectkbest dengan menggunakan mutual information lalu fitur yang dideleksi adalah semua fitur\nselector = SelectKBest(score_func=mutual_info_classif, k='all') \n# untuk mengubah dataset fitur menjadi X_new, yang hanya berisi fitur terbaik yang dipilih oleh SelectKBest berdasarkan skor yang dihitung sebelumnya.\nX_new = selector.fit_transform(fitur_balance,target_balance)\n# Mengambil skor dari fitur-fitur dalam dataset. Skor-skor ini merepresentasikan informasi gain atau kepentingan setiap fitur terhadap label kelas.\nscores = selector.scores_\n\n# Menyimpan skor fitur dan nama fitur dalam variabel terpisah untuk digunakan dalam visualisasi.\nfeature_scores = selector.scores_\nfeature_names = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n       'pH', 'sulphates', 'alcohol']\n\n# Mengurutkan indeks fitur berdasarkan skor fitur dari yang tertinggi ke terendah.\nsorted_indices = feature_scores.argsort()[::-1]\n\n# Mengurutkan skor fitur dan nama fitur sesuai dengan indeks yang telah diurutkan sebelumnya.\nsorted_scores = feature_scores[sorted_indices]\nsorted_feature_names = [feature_names[i] for i in sorted_indices]\n\n# Plot the feature importances\n# digunakan untuk membuat diagram batang yang merepresentasikan skor fitur.\nplt.figure(figsize=(12, 6))\nplt.bar(range(len(sorted_feature_names)), sorted_scores)\n# digunakan untuk menambahkan label pada sumbu x (fitur) dengan rotasi 90 derajat agar lebih mudah dibaca.\nplt.xticks(range(len(sorted_feature_names)), sorted_feature_names, rotation=90)\n# Label sumbu x adalah nama fitur, sedangkan label sumbu y adalah skor fitur (information gain).\nplt.xlabel('Features')\nplt.ylabel('Information Gain')\nplt.title('Feature Importance (Information Gain)') # memberikan judul plot.\nplt.show() # menampilkan plot.\n\n\n\n\nSetelah itu dilakukan skenario percobaan , diketahui bahwa fitur yang terbaik untuk digunakan dalam klasifikasi data red wine, diantaranya\n\nfixed acidity\nvolatile acidity\ncitric acid\nresidual sugar\nchlorides\nfree sulfur dioxide\ntotal sulfur dioxide\ndensity\npH\nsulphates\nalcohol"
  },
  {
    "objectID": "winequality.html#modeling",
    "href": "winequality.html#modeling",
    "title": "1  ———————– TUGAS PROYEK SAINS DATA ————————",
    "section": "1.4 MODELING",
    "text": "1.4 MODELING\n\nTahap modeling dalam analisis data adalah tahap dimana digunakannya berbagai teknik dan algoritma untuk membangun model prediktif atau deskriptif dari data yang telah siapkan. Ini merupakan salah satu langkah penting dalam proses analisis data dan umumnya terdiri dari beberapa langkah, tergantung pada jenis analisis yang dilakukan.\n\n1.4.1 RANDOM FOREST\n\nRandom Forest adalah algoritma pembelajaran terawasi yang digunakan untuk tugas klasifikasi dan regresi dalam machine learning. Ini merupakan bagian dari keluarga algoritma yang dikenal sebagai ensemble learning, yang menggabungkan hasil beberapa model untuk meningkatkan kinerja dan ketepatan prediksi.\nKonsep inti dari Random Forest adalah membuat sejumlah besar pohon keputusan saat melakukan prediksi. Setiap pohon keputusan dibuat berdasarkan sampel acak dari data pelatihan dan fitur yang dipilih secara acak. Proses ini mengurangi risiko overfitting (memfitting data pelatihan secara berlebihan) yang sering terjadi pada pohon keputusan tunggal.\nSelama proses pelatihan, setiap pohon keputusan dalam hutan acak memilih subset data yang diambil secara acak dan subset fitur untuk membuat keputusan. Ketika melakukan prediksi, setiap pohon memberikan hasilnya, dan hasil akhir dari Random Forest diperoleh dengan mengambil mayoritas suara dari semua pohon keputusan (untuk klasifikasi) atau rerata hasil (untuk regresi).\nKelebihan dari Random Forest termasuk kemampuannya dalam menangani data yang besar dengan fitur yang banyak, serta kemampuan untuk mengatasi overfitting. Namun, seperti halnya dengan banyak algoritma machine learning, pengaturan parameter yang tidak tepat atau kekurangan pemrosesan data yang tepat dapat mempengaruhi kinerja Random Forest.\nPrinsip kerja utama algoritma Random Forest\n\nPemilihan Sampel Acak (Random Sampling):\n\nDari dataset yang ada, Random Forest melakukan sampling acak dengan penggantian (bootstrap sampling) untuk membuat dataset yang lebih kecil namun representatif. Hal ini membantu dalam membangun berbagai pohon keputusan yang berbeda.\n\nPembangunan Pohon Keputusan (Decision Tree):\n\nSetiap pohon keputusan dibangun menggunakan subset dari data yang diambil secara acak pada langkah pertama. Pohon-pohon ini dibuat dengan membagi data berulang-ulang berdasarkan fitur-fitur yang tersedia, untuk membuat keputusan yang optimal pada setiap simpulnya.\n\nVoting atau Penggabungan (Voting or Aggregation):\n\nSetelah semua pohon keputusan selesai dibuat, hasil prediksi dari setiap pohon dikumpulkan. Pada tahap ini, jika masalahnya adalah klasifikasi, hasilnya diambil dengan cara mayoritas (melalui voting), sedangkan untuk regresi, hasilnya bisa diambil dengan rata-rata dari prediksi semua pohon.\n\nPengukuran Keakuratan (Accuracy Measurement):\n\nUntuk menentukan hasil akhir, model menghasilkan prediksi berdasarkan mayoritas suara dari semua pohon keputusan (untuk klasifikasi) atau nilai rata-rata (untuk regresi). Keakuratan model kemudian diukur dengan membandingkan prediksi tersebut dengan nilai sebenarnya dari data yang tidak terlibat dalam pelatihan.\nParameter Algoritma Random Forest\nJika ingin mengimplementasikan algoritma Random Forest dalam kasus klasifikasi, maka terdapat parameter-parameter yang perlu diperhatikan diantaranya : Parameter-parameter yang perlu diperhatikan saat membangun algoritma Random Forest adalah sebagai berikut:\n\nJumlah Pohon (n_estimators)\n\nIni adalah jumlah pohon keputusan yang ingin Anda bangun dalam Random Forest. Semakin banyak pohon, biasanya hasilnya akan lebih baik, namun akan memakan lebih banyak waktu komputasi.\n\nKedalaman Pohon (max_depth)\n\nMenentukan kedalaman maksimum dari setiap pohon keputusan dalam ensemble. Kedalaman yang terlalu dalam dapat menyebabkan overfitting.\n\nMin_samples_split dan min_samples_leaf\n\nMenentukan jumlah sampel minimum yang diperlukan untuk membagi node internal atau menjadi daun (leaf node) dalam pohon.\nUntuk mencari parameter terbaik dalam klasifikasi dengan menggunakan metode Random Forest dapat menggunakan metode bantuan untuk mencari parameter terbaik yang akan digunakan dalam kasus klasifikasi data red wine. Pada proyek ini digunakan metode GridSearch CV untuk menemukan parameter yang optimal dan terbaik untuk metode Random Forest seperti mencari jumlah pohon,kedalaman pohon, minmal pembagian sampel dan pembagian daun.\n\n\n1.4.2 GridSearchCV\n\nadalah metode yang digunakan untuk menemukan parameter yang optimal bagi suatu model dalam machine learning dengan menggunakan validasi silang (cross-validation).GridSearchCV bekerja dengan melakukan pencarian parameter terbaik yang diberikan dalam rentang nilai yang telah ditentukan sebelumnya. Ini dilakukan dengan cara menguji semua kombinasi yang mungkin dari parameter-parameter yang diinginkan dan mengevaluasi performa model menggunakan teknik validasi silang untuk setiap kombinasi parameter.\nLangkah-langkah umum yang dilakukan oleh GridSearchCV adalah sebagai berikut:\n\nSpesifikasi Model dan Parameter: Tentukan model yang ingin Anda gunakan serta parameter apa yang ingin Anda uji. Misalnya, jika Anda menggunakan model Random Forest, parameter seperti jumlah pohon, kedalaman maksimum, dan fitur yang harus dipertimbangkan.\nDefinisikan Grid Parameter: Buat daftar parameter yang ingin diuji dengan rentang nilai-nilai yang berbeda untuk setiap parameter. Ini membentuk sebuah grid atau kisi dari kombinasi parameter-parameter yang mungkin.\nCross-Validation: Gunakan teknik validasi silang (biasanya K-Fold Cross-Validation) untuk membagi data menjadi subset pelatihan dan validasi. Setiap kombinasi parameter akan dievaluasi pada setiap lipatan untuk mendapatkan skor evaluasi.\nPemilihan Parameter Terbaik: Setelah proses validasi selesai, GridSearchCV akan menentukan kombinasi parameter terbaik yang memberikan performa terbaik sesuai dengan metrik evaluasi yang telah ditentukan sebelumnya (misalnya, akurasi, F1-score, dll.).\nPenggunaan Model Terbaik: Setelah menemukan parameter terbaik, Anda dapat menggunakan model dengan parameter tersebut untuk membuat prediksi pada data baru\n\nSetelah dilakukan skenario perulangan untuk menghasilkan model terbaik, dapat diketahui bahwasannya model klasifikasi yang terbaik untuk data anggur merah ini adalah dengan menggunakan\n\nMetode Random Forest\nMetode normalisasi nya adalah MINMAX Scaler\nBanyak Fitur yang digunakan dalam data sebanyak 11 fitur\n\n\n# Define the parameter grid for Random Forest\nparam_grid = {\n    'n_estimators': [100, 200, 300],  # You can adjust the number of trees\n    'max_depth': [None, 10, 20, 30],  # You can adjust the maximum depth of each tree\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Create a Random Forest model\nrandom_forest = RandomForestClassifier()\n\n# MINMAX\ngrid_search2 = GridSearchCV(estimator=random_forest, param_grid=param_grid, cv=5, scoring='accuracy')\ngrid_search2.fit(minmax_training, target_train)\nprint(\"Best Parameters MINMAX:\", grid_search2.best_params_)\nbest_n_estimators_minmax = grid_search2.best_params_['n_estimators']\nbest_max_depth_minmax = grid_search2.best_params_['max_depth']\nbest_min_samples_split_minmax = grid_search2.best_params_['min_samples_split']\nbest_min_samples_leaf_minmax = grid_search2.best_params_['min_samples_leaf']\n\nprint(\"Parameter dalam metode yang digunakan, sebagai berikut \\n\")\nprint(\"jumlah best estimator  :\",best_n_estimators_minmax,\"\\n\")\nprint(\"best maksimal kedalaman  :\",best_max_depth_minmax,\"\\n\")\nprint(\"best minimal pembagian sampel  :\",best_min_samples_split_minmax,\"\\n\")\nprint(\"best minimal sampel daun  :\",best_min_samples_leaf_minmax,\"\\n\")\n\nBest Parameters MINMAX: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\nParameter dalam metode yang digunakan, sebagai berikut \n\njumlah best estimator  : 300 \n\nbest maksimal kedalaman  : 30 \n\nbest minimal pembagian sampel  : 2 \n\nbest minimal sampel daun  : 1 \n\n\n\n\n# MINMAX\n#membuat model klasifikasi Random Forest dari parameter terbaik yang telah diketahui di proses sebelumnya\nmodel_rf_minmax = RandomForestClassifier( max_depth= best_max_depth_minmax,min_samples_leaf= best_min_samples_leaf_minmax,min_samples_split= best_min_samples_split_minmax, n_estimators= best_n_estimators_minmax)\n# Melatih model RandomForestClassifier dengan dataset latihan (minmax_training) yang telah dinormalisasi dan labelnya (target_train).\nmodel_rf_minmax.fit(minmax_training, target_train)\n# Menggunakan model yang telah dilatih untuk melakukan prediksi pada dataset pengujian (minmax_testing) yang juga telah dinormalisasi.\ny_pred_minmax = model_rf_minmax.predict(minmax_testing)\n# Menghitung akurasi dari prediksi yang dilakukan oleh model RandomForestClassifier \naccuracy_rf_minmax = accuracy_score(target_test, y_pred_minmax)\n\nprint(\"AKURASI RANDOM FOREST\")\nprint(\"AKURASI minmax :\",accuracy_rf_minmax)\n\nAKURASI RANDOM FOREST\nAKURASI minmax : 0.9377162629757786\n\n\n\n\n1.4.3 SIMPAN MODEL KLASIFIKASI\nUntuk keperluan Prediksi nanti pada tahap Deployment, maka model terbaik yang telah diterapkan saat ini disimpan untuk kasus prediksi kualitas red wine kedepannya sehingga tidak perlu lagi mencari-cari model terbaik untuk melakukan prediksi pada data uji baru nantinya\n\nwith open('best_model_rf_minmax.pkl', 'wb') as model_file:\n    pickle.dump(model_rf_minmax,model_file)"
  },
  {
    "objectID": "winequality.html#evaluasi-model",
    "href": "winequality.html#evaluasi-model",
    "title": "1  ———————– TUGAS PROYEK SAINS DATA ————————",
    "section": "1.5 EVALUASI MODEL",
    "text": "1.5 EVALUASI MODEL\n\nTahap evaluasi model adalah langkah penting dalam proses pembangunan model prediktif atau deskriptif untuk memastikan bahwa model yang dibuat dapat memberikan hasil yang berguna dan akurat. Evaluasi model dilakukan setelah proses pelatihan model untuk memahami seberapa baik model tersebut dapat melakukan prediksi atau generalisasi pada data yang belum pernah dilihat sebelumnya.\nPada tahap ini model terbaik yang diperoleh pada tahap modeling dilakukan validasi dengan menampilkan nilai confusion matrix nya atau laporan klasifikasinya dengan menampilkan grafik ROC-AUC\nHASIL TABEL KEBINGUNGAN DAN MATRIKS EVALUASI\n\nPada tahap ini dilakukan evaluasi terhadap model terbaik yang telah dibuat pada tahap modelling sebelumnya, sehingga menghasilkan beberapa evaluasi yang di representasikan dalam bentuk Tabel Kebingungan maupun Matriks Evaluasi:\nTabel Kebingungan\nDidalam Tabel Kebingungan dihasilkan nilai dari TP,FP,FN dan TN seperti berikut:\n\nTrue Positive (TP): 342\nTrue Negative (TN): 317\nFalse Positive (FP): 17\nFalse Negative (FN): 3\n\nMatriks Evaluasi\nDidalam Matriks Evaluasi dapat diketahui nilai-nilai dari beberapa bagian di matriks Evaluasi diantaranya :\n\nAkurasi Model : 0.97\nScore ROC-AUC : 0.9702\nNilai Presisi, Recall, F1-Score dan Support setiap kelas yang terdapat didalam data:\n\n\n\n\n\nPesisi\nRecall\nf1-score\n\n\n\n\nKualitas Baik\n0.95\n0.95\n0.97\n\n\nKualitas Buruk\n0.99\n0.99\n0.97\n\n\n\nHASIL INTERPRETASI ROC-AUC\n\nDari kurva ROC yang dihasilkan dapat disimpulkan bahwasannya nilai AUC lebih mendekati nilai 1, hal ini menandakan bahwasannya model yang diterapkan mampu membedakan antara kelas porsitif dan kelas negatif dengan baik.\n\n1.5.1 CONFUSION MATRIX\n\nConfusion matrix adalah sebuah tabel yang digunakan dalam evaluasi kinerja model klasifikasi untuk memahami performa model dalam memprediksi kelas-kelas target. Matrix ini memiliki empat sel yang mewakili:\n\nTrue Positive (TP): Prediksi yang benar ketika kelas sebenarnya adalah positif.\nTrue Negative (TN): Prediksi yang benar ketika kelas sebenarnya adalah negatif.\nFalse Positive (FP): Prediksi yang salah ketika model memprediksi positif tetapi kelas sebenarnya negatif (juga dikenal sebagai Type I error).\nFalse Negative (FN): Prediksi yang salah ketika model memprediksi negatif tetapi kelas sebenarnya positif (juga dikenal sebagai Type II error).\n\nBentuk dari tabel Confusion Matrix\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\nTrue Negative (TN)\nFalse Positive (FP)\n\n\nActual Positive\nFalse Negative (FN)\nTrue Positive (TP)\n\n\n\nDari Confusion Matriks, kta dapat menghitung metrik evaluasi seperti akurasi, presisi, recall, F1-score, dan lainnya yang membantu dalam mengevaluasi performa model klasifikasi.\nMETRIKS EVALUASI\n\nMetrik evaluasi adalah ukuran atau parameter yang digunakan untuk mengevaluasi kinerja suatu model atau sistem dalam melakukan tugas tertentu, seperti klasifikasi, regresi, atau tugas lainnya dalam bidang machine learning dan statistika. Metrik-metrik ini membantu dalam memahami seberapa baik atau buruk model tersebut dalam melakukan prediksi atau tugas yang ditetapkan.\nBeberapa metrik evaluasi umum dalam machine learning termasuk:\n\nAkurasi (Accuracy): Seberapa sering model memberikan prediksi yang benar secara keseluruhan.\n\nRumus Akurasi :\n\\[ Accuracy = \\frac{TN + TP}{TN + FP + FN + TP} \\]\n\nPresisi (Precision): Proporsi dari prediksi positif yang benar dibandingkan dengan semua prediksi positif yang dibuat oleh model\n\nRumus Precision :\n\\[ Precision = \\frac{TP}{TP + FP} \\]\n\nRecall (Sensitivity atau True Positive Rate): Proporsi dari kelas positif yang diprediksi dengan benar oleh model.\n\nRumus Recall :\n\\[ Recall = \\frac{TP}{TP + FN} \\]\n\nF1-Score: Nilai rata-rata harmonik antara presisi dan recall. Berguna ketika perlu menyeimbangkan antara presisi dan recall.\n\nRumus F1-Score :\n\\[ F1-Score = 2 × \\frac {Presisi × Recall}{Presisi × Recall} \\]\n\nSpecificity (Specificity atau True Negative Rate): Proporsi dari kelas negatif yang diprediksi dengan benar oleh model.\n\nRumus Specificity :\n\\[ Specificity = \\frac{TN}{TN + FP} \\]\n\n\n# Evaluasi model dengan data uji MINMAX\nprint(\"\\nEVALUASI MODEL DENGAN DATA UJI ZSCORE\")\nprint(\"Confusion Matrix ZSCORE:\")\n# menghiung confusion matriks antara target aktual hasil prediksi\nconf_matrix = confusion_matrix(target_test, y_pred_minmax)\nprint(conf_matrix)\n\n# Mendapatkan nilai TP, TN, FP, FN dari confusion matrix\nTN = conf_matrix[0, 0] # mengambil nilai TN dalam matriks\nFP = conf_matrix[0, 1] # mengambil nilai FP dalam matriks\nFN = conf_matrix[1, 0] # mengambil nilai FN dalam matriks\nTP = conf_matrix[1, 1] # mengambil nilai TP dalam matriks\n\nprint(\"\\nTrue Positive (TP):\", TP) # menampilkan nilai True Positive\nprint(\"True Negative (TN):\", TN) # menampilkan nilai True Negative\nprint(\"False Positive (FP):\", FP) # menampilkan nilai False Positive\nprint(\"False Negative (FN):\", FN) # menampilkan nilai False Negative\n\nprint(\"\\nClassification Report ZSCORE:\")\nprint(classification_report(target_test, y_pred_minmax)) # mencetak laporan klasifikasi yang lengkap.\n# Ini akan mencetak skor ROC-AUC (Area Under the Receiver Operating Characteristic Curve) dari model klasifikasi untuk data pengujian. \nprint(\"ROC-AUC Score MINMAX:\", roc_auc_score(target_test, y_pred_minmax)) \n\n\nEVALUASI MODEL DENGAN DATA UJI ZSCORE\nConfusion Matrix ZSCORE:\n[[258  36]\n [  0 284]]\n\nTrue Positive (TP): 284\nTrue Negative (TN): 258\nFalse Positive (FP): 36\nFalse Negative (FN): 0\n\nClassification Report ZSCORE:\n              precision    recall  f1-score   support\n\n           0       1.00      0.88      0.93       294\n           1       0.89      1.00      0.94       284\n\n    accuracy                           0.94       578\n   macro avg       0.94      0.94      0.94       578\nweighted avg       0.94      0.94      0.94       578\n\nROC-AUC Score MINMAX: 0.9387755102040816\n\n\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nconf_matrix = confusion_matrix(target_test, y_pred_minmax)\n\nplt.figure(figsize=(6, 4))\nsns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()\n\n\n\n\n\n\n1.5.2 GRAFIK ROC-AUC\n\nMetrik evaluasi ROC (Receiver Operating Characteristic) dan AUC (Area Under the ROC Curve) adalah alat evaluasi yang digunakan untuk mengukur kinerja model klasifikasi, terutama ketika model harus mengklasifikasikan antara dua kelas.\nReceiver Operating Characteristic (ROC) Curve\nROC Curve adalah adalah kurva grafik yang menampilkan kinerja model klasifikasi pada berbagai tingkat cutoff (threshold) untuk membedakan antara kelas positif dan negatif. Didalam ROC kurva dapat diketahui sensitivity (True Positive Rate) dan False Positive Rate (1-Specificity), untuk menunjukkan seberapa baik model klasifikasi sehingga dapat membedakan antara kelas positif dan negatif.\nArea Under the ROC Curve (AUC-ROC)\nAUC-ROC adalah ukuran dari luas area di bawah kurva ROC.\n\nInterpretasi :\n\nNilai AUC berkisar antara 0 hingga 1. Semakin dekat nilainya ke 1, semakin baik model dalam membedakan antara kelas positif dan negatif. Jika nilainya 0.5, itu menunjukkan klasifikasi acak.\n\n# Kurva ROC-AUC untuk model dengan data uji minmax\n# Menghitung False Positive Rate (FPR), True Positive Rate (TPR), dan threshold untuk kurva ROC. \n# target_test adalah label yang sebenarnya dari data pengujian, sedangkan y_pred_minmax adalah hasil prediksi model terhadap data pengujian.\nfpr_minmax, tpr_minmax, thresholds_minmax = roc_curve(target_test, y_pred_minmax)\n# Membuat figur (plot) dengan ukuran 8x6 inci.\nplt.figure(figsize=(8, 6))\n# Membuat plot untuk kurva ROC dengan sumbu x sebagai FPR dan sumbu y sebagai TPR.\nplt.plot(fpr_minmax, tpr_minmax, label='ROC Curve minmax (area = %0.2f)' % roc_auc_score(target_test, y_pred_minmax))\n# Membuat garis putus-putus yang mewakili kurva ROC jika model tidak memiliki kemampuan prediktif (keberuntungan acak).\nplt.plot([0, 1], [0, 1], 'k--')\n# Menambahkan label sumbu x dan y pada plot untuk menunjukkan apa yang direpresentasikan oleh sumbu tersebut.\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\n# Memberikan judul pada plot, menunjukkan bahwa ini adalah kurva ROC untuk model dengan data pengujian yang telah dinormalisasi menggunakan metode Min-Max.\nplt.title('Receiver Operating Characteristic (ROC) Curve MINMAX')\n# Menampilkan legenda di pojok kanan bawah plot, menunjukkan informasi tambahan tentang kurva yang digambarkan.\nplt.legend(loc='lower right')\nplt.show() #  Menampilkan plot kurva ROC yang telah dibuat."
  },
  {
    "objectID": "winequality.html#deployment",
    "href": "winequality.html#deployment",
    "title": "1  ———————– TUGAS PROYEK SAINS DATA ————————",
    "section": "1.6 DEPLOYMENT",
    "text": "1.6 DEPLOYMENT\n\nTahap deployment dalam konteks analisis data atau pengembangan model mengacu pada proses menerapkan atau menempatkan model yang telah dibuat ke dalam lingkungan produksi atau ke dalam penggunaan praktis di dunia nyata.\nPenerapan model akan diimplementasikan untuk melakukan prediksi kualitas red wine. Setelah ini tahap berpindah ke aplikasi streamlit.py\n–&gt;"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  }
]